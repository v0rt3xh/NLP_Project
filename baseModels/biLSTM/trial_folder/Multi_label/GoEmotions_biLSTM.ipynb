{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rv8YnVHBlET-"
      },
      "source": [
        "# GoEmotions: Trial Using biLSTM\n",
        "\n",
        "This implementation is based on tensorflow. We use the tutorial released by the authors of GoEomotions as a reference for processing the data. We adapt some of their helper methods. [Reference Link](https://github.com/tensorflow/models/blob/master/research/seq_flow_lite/demo/colab/emotion_colab.ipynb)\n",
        "\n",
        "As for modeling part, we build our model based on Keras' APIs. We also include the embedding weights from GloVe. We will give a detailed explanation of the pre-trained embedding in the corresponding sections."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "kTSd3Wo6CPJT"
      },
      "outputs": [],
      "source": [
        "# Load libraries\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5wwnY_v9BkE"
      },
      "source": [
        "Here, we directly load the GoEmotions dataset from Tensorflow Dataset. The dataset is the one originally released by the authors. [Link to Description](https://www.tensorflow.org/datasets/catalog/goemotions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vzq7XWL0CbWC"
      },
      "outputs": [],
      "source": [
        "train_ds = tfds.load('goemotions', split='train')\n",
        "val_ds = tfds.load('goemotions', split='validation')\n",
        "test_ds = tfds.load('goemotions', split='test')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zfJ8UUT6_73Y",
        "outputId": "489ab30c-29eb-4014-ad5d-ac2359e787cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'admiration': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'amusement': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'anger': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'annoyance': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'approval': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'caring': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'comment_text': <tf.Tensor: shape=(), dtype=string, numpy=b\"It's just wholesome content, from questionable sources\">, 'confusion': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'curiosity': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'desire': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'disappointment': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'disapproval': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'disgust': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'embarrassment': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'excitement': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'fear': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'gratitude': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'grief': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'joy': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'love': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'nervousness': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'neutral': <tf.Tensor: shape=(), dtype=bool, numpy=True>, 'optimism': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'pride': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'realization': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'relief': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'remorse': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'sadness': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'surprise': <tf.Tensor: shape=(), dtype=bool, numpy=False>}\n",
            "{'admiration': <tf.Tensor: shape=(), dtype=bool, numpy=True>, 'amusement': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'anger': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'annoyance': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'approval': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'caring': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'comment_text': <tf.Tensor: shape=(), dtype=string, numpy=b'This is actually awesome.'>, 'confusion': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'curiosity': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'desire': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'disappointment': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'disapproval': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'disgust': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'embarrassment': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'excitement': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'fear': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'gratitude': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'grief': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'joy': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'love': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'nervousness': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'neutral': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'optimism': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'pride': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'realization': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'relief': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'remorse': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'sadness': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'surprise': <tf.Tensor: shape=(), dtype=bool, numpy=False>}\n",
            "{'admiration': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'amusement': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'anger': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'annoyance': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'approval': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'caring': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'comment_text': <tf.Tensor: shape=(), dtype=string, numpy=b\"People really spend more than $10 in an app game? I mean an actual video game I can understand but that's just...sad\">, 'confusion': <tf.Tensor: shape=(), dtype=bool, numpy=True>, 'curiosity': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'desire': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'disappointment': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'disapproval': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'disgust': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'embarrassment': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'excitement': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'fear': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'gratitude': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'grief': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'joy': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'love': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'nervousness': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'neutral': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'optimism': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'pride': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'realization': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'relief': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'remorse': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'sadness': <tf.Tensor: shape=(), dtype=bool, numpy=True>, 'surprise': <tf.Tensor: shape=(), dtype=bool, numpy=False>}\n",
            "{'admiration': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'amusement': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'anger': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'annoyance': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'approval': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'caring': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'comment_text': <tf.Tensor: shape=(), dtype=string, numpy=b'I grew up on the other side of Ama but live in Tulia now. I will have some El Burrito for you'>, 'confusion': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'curiosity': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'desire': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'disappointment': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'disapproval': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'disgust': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'embarrassment': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'excitement': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'fear': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'gratitude': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'grief': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'joy': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'love': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'nervousness': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'neutral': <tf.Tensor: shape=(), dtype=bool, numpy=True>, 'optimism': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'pride': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'realization': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'relief': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'remorse': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'sadness': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'surprise': <tf.Tensor: shape=(), dtype=bool, numpy=False>}\n",
            "{'admiration': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'amusement': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'anger': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'annoyance': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'approval': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'caring': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'comment_text': <tf.Tensor: shape=(), dtype=string, numpy=b'What the problem? I mean, steak? Good. Doughnuts? Good!! I don\\xe2\\x80\\x99t see an issue. '>, 'confusion': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'curiosity': <tf.Tensor: shape=(), dtype=bool, numpy=True>, 'desire': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'disappointment': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'disapproval': <tf.Tensor: shape=(), dtype=bool, numpy=True>, 'disgust': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'embarrassment': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'excitement': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'fear': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'gratitude': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'grief': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'joy': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'love': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'nervousness': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'neutral': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'optimism': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'pride': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'realization': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'relief': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'remorse': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'sadness': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'surprise': <tf.Tensor: shape=(), dtype=bool, numpy=False>}\n"
          ]
        }
      ],
      "source": [
        "# Check the format of the tensorflow dataset.\n",
        "for element in train_ds.take(5):\n",
        "  print(element)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We consider the full taxonomy. There are 27 emotions plus a neutral class. "
      ],
      "metadata": {
        "id": "6kVF6DCgUbLO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ju6YkTseLEe6"
      },
      "outputs": [],
      "source": [
        "# the 28 emotions in our dataset\n",
        "LABELS = [\n",
        "    'admiration',\n",
        "    'amusement',\n",
        "    'anger',\n",
        "    'annoyance',\n",
        "    'approval',\n",
        "    'caring',\n",
        "    'confusion',\n",
        "    'curiosity',\n",
        "    'desire',\n",
        "    'disappointment',\n",
        "    'disapproval',\n",
        "    'disgust',\n",
        "    'embarrassment',\n",
        "    'excitement',\n",
        "    'fear',\n",
        "    'gratitude',\n",
        "    'grief',\n",
        "    'joy',\n",
        "    'love',\n",
        "    'nervousness',\n",
        "    'optimism',\n",
        "    'pride',\n",
        "    'realization',\n",
        "    'relief',\n",
        "    'remorse',\n",
        "    'sadness',\n",
        "    'surprise',\n",
        "    'neutral',\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the section below, we define a helper method that take in the original label and return an one-hot vector."
      ],
      "metadata": {
        "id": "-9t0UnCZUksU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "c2y9uhTHO4rp"
      },
      "outputs": [],
      "source": [
        "# Construct training dataset & validation dataset needed for the biLSTM model\n",
        "def process_label(features):\n",
        "  '''\n",
        "  Preprocess function. This will be an entry for the map function of tf.data.dataset \n",
        "  We create the label vector first.\n",
        "  input:\n",
        "    features, each entry in the dataset\n",
        "  output:\n",
        "    A dictionary (like the original input)\n",
        "  '''\n",
        "  text = features['comment_text'] # Text's key in GoEmotions\n",
        "  label = tf.stack([features[label] for label in LABELS], axis=-1)\n",
        "  label = tf.cast(label, tf.float32)\n",
        "  model_features = (text, label)\n",
        "  return model_features\n",
        "\n",
        "# This was used for debugging (Check our process_label method is correct)\n",
        "# tf.dataset's map function just apply the callback / function to each element in the dataset.\n",
        "trial_ds = train_ds.map(process_label, num_parallel_calls=tf.data.experimental.AUTOTUNE, deterministic=False)\n",
        "\n",
        "# Create Vocabulary\n",
        "# We use at most 50000 words\n",
        "MAX_FEATURES = 50000\n",
        "# Restrict the length of sentences to 256\n",
        "MAX_LENGTH = 300\n",
        "\n",
        "# We use keras' text vectorization layer\n",
        "# like the Vocab class we used in assignment 2\n",
        "vectorized_layer = tf.keras.layers.TextVectorization(max_tokens=MAX_FEATURES, output_sequence_length=MAX_LENGTH)\n",
        "# Add all the training vocabularies\n",
        "vectorized_layer.adapt(train_ds.map(lambda text: text['comment_text']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tTi7unTiLa5g",
        "outputId": "14f329f2-47ec-4069-c170-70ff1d5ec600"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['', '[UNK]', 'the', 'i', 'to', 'a', 'you', 'and', 'is', 'that'],\n",
              "      dtype='<U633')"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# sanity check, the elements with most appearance\n",
        "glance_vocab = np.array(vectorized_layer.get_vocabulary())\n",
        "glance_vocab[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "6VPl_RmI2c2O"
      },
      "outputs": [],
      "source": [
        "# Create the training set, validation set\n",
        "BUFFER_SIZE = 60000\n",
        "BATCH_SIZE = 64\n",
        "trial_train_ds = train_ds.map(process_label, num_parallel_calls=tf.data.experimental.AUTOTUNE, deterministic=False)\n",
        "trial_val_ds = val_ds.map(process_label, num_parallel_calls=tf.data.experimental.AUTOTUNE, deterministic=False)\n",
        "train_dataset = trial_train_ds.shuffle(BUFFER_SIZE).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "val_dataset = trial_val_ds.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e2_2DUqq3B69"
      },
      "outputs": [],
      "source": [
        "# sanity check\n",
        "for example, label in val_dataset.take(1):\n",
        "  print('texts: ', example)\n",
        "  print()\n",
        "  print('labels: ', label)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qzq77fTw6zbf"
      },
      "source": [
        "# Load Embeddings\n",
        "\n",
        "We use the embeddings from GLoVe. To be more specific, we choose  glove.twitter.27B with embedding dimension $200$. In this section, we load the embeddings from Google Drive to the embedding layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ASxg43dO-5mz",
        "outputId": "ca0014d6-f977-4da8-9782-815ae721f7bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "1193514\n"
          ]
        }
      ],
      "source": [
        "import os \n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "embedding_file = open('/content/drive/MyDrive/glove.twitter.27B.200d.txt')\n",
        "embedding_dict = {}\n",
        "for row in embedding_file:\n",
        "  values = row.split()\n",
        "  word = values[0]\n",
        "  embedding_vec = np.asarray(values[1:], dtype='float32')\n",
        "  embedding_dict[word] = embedding_vec\n",
        "embedding_file.close()\n",
        "print(len(embedding_dict))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "5AMQkdG_U8e1"
      },
      "outputs": [],
      "source": [
        "# Coordinate with the previous vocabulary\n",
        "current_words = vectorized_layer.get_vocabulary()\n",
        "EMBEDDING_DIM = 200\n",
        "embedding_weights = np.zeros((len(current_words), EMBEDDING_DIM))\n",
        "for i, words in enumerate(current_words):\n",
        "  embedding_word = embedding_dict.get(words)\n",
        "  if embedding_word is not None:\n",
        "    embedding_weights[i] = embedding_word\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q8krHjSTR1sU"
      },
      "source": [
        "# Build the model\n",
        "\n",
        "In the following section, we define the biLSTM architecture. The model starts with the tokenization layer and embedding layer. We set the dimension of embedding layer as $200$. The weights are loaded from GLoVe and are trainable. Then, we include two biLSTM units with hidden dimension $256$. \n",
        "\n",
        "The output of the biLSTM units are fed to two fully connected layers. Between the fully connected layers, we add a dropout layer with dropout probability $0.7$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "FskiuRASxLuh"
      },
      "outputs": [],
      "source": [
        "NUM_OF_CLASSES = 28\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "EQkRp-aR96Qk"
      },
      "outputs": [],
      "source": [
        "biLSTM_model = tf.keras.Sequential([\n",
        "                           vectorized_layer,\n",
        "                           tf.keras.layers.Embedding(\n",
        "                               input_dim=len(vectorized_layer.get_vocabulary()),\n",
        "                               output_dim=200,\n",
        "                               mask_zero = True,\n",
        "                               weights = [embedding_weights],\n",
        "                               trainable=True\n",
        "                           ),\n",
        "                           tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(256, return_sequences=True)),\n",
        "                           tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(256)),\n",
        "                           tf.keras.layers.Dense(512, activation='relu'),\n",
        "                           tf.keras.layers.Dropout(0.7),\n",
        "                           tf.keras.layers.Dense(NUM_OF_CLASSES)\n",
        "                           ])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pnmHUaIc_6jA"
      },
      "source": [
        "# Train the model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We choose Adam as the optimizer and a learning rate of $0.001$. Since we are considering multi-class multi-label predictions, we use the binary cross entropy loss.  "
      ],
      "metadata": {
        "id": "DEozoIDVRVP4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 1e-3\n",
        "loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=lr)"
      ],
      "metadata": {
        "id": "61tT6ULepn7U"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "swQ8UNV1ysgu"
      },
      "outputs": [],
      "source": [
        "biLSTM_model.compile(loss=loss,\n",
        "              optimizer=optimizer,\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "jpr14h80YFb7"
      },
      "outputs": [],
      "source": [
        "# Use a callback to store best models.\n",
        "checkpoint_dir = '/content/drive/MyDrive/cs769-project/output'\n",
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_dir,\n",
        "    save_weights_only=True,\n",
        "    monitor='val_accuracy',\n",
        "    mode='max',\n",
        "    save_best_only=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "flOc1CKP5n6B"
      },
      "outputs": [],
      "source": [
        "history = biLSTM_model.fit(train_dataset, epochs=15,\n",
        "                    validation_data=val_dataset,\n",
        "                    validation_steps=30,\n",
        "                    callbacks=[model_checkpoint_callback])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ha4pvwUO05sn"
      },
      "source": [
        "# Evaluation\n",
        "\n",
        "We compute recall, precision and F-1 scores."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "iFfeYF-vAgeD"
      },
      "outputs": [],
      "source": [
        "pred_result = biLSTM_model.predict(val_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We record the true labels and the predicted labels. This could be a separate helper method though. We will modularize the notebook later. "
      ],
      "metadata": {
        "id": "u88mOkneSKsz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "ScXyuCwgCvpk"
      },
      "outputs": [],
      "source": [
        "pred_y = []\n",
        "actual_y = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "fWoIOjKLChNn"
      },
      "outputs": [],
      "source": [
        "i = 0 \n",
        "for _, labels in val_dataset:\n",
        "  for label in labels.numpy():\n",
        "    pred_label = tf.cast(tf.math.sigmoid(pred_result[i]) > 0.5, tf.float32).numpy()\n",
        "    i += 1\n",
        "    pred_y.append(pred_label)\n",
        "    actual_y.append(label)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, we are showing the average F-1 score on the validation set."
      ],
      "metadata": {
        "id": "xHcgBR72Sbfz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Zs6ppcKH5wj",
        "outputId": "f78a8521-d558-4441-fe3a-4008813be605"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.4177191178798451\n",
            "[0.64754098 0.78547855 0.34871795 0.28052805 0.26448363 0.33986928\n",
            " 0.23684211 0.33064516 0.35064935 0.17177914 0.18493151 0.43298969\n",
            " 0.45714286 0.21875    0.44444444 0.87150838 0.07692308 0.51744186\n",
            " 0.79761905 0.23809524 0.50717703 0.26666667 0.21259843 0.05555556\n",
            " 0.54411765 0.53146853 0.43410853 0.52718007]\n",
            "[0.60652591 0.72340426 0.5112782  0.24781341 0.28767123 0.33548387\n",
            " 0.31034483 0.31417625 0.52941176 0.19178082 0.32335329 0.43298969\n",
            " 0.66666667 0.27272727 0.61538462 0.91764706 0.5        0.54938272\n",
            " 0.71530249 0.33333333 0.56084656 0.66666667 0.16071429 0.2\n",
            " 0.64912281 0.47798742 0.46280992 0.55949519]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import f1_score, recall_score, precision_score\n",
        "f1_score_list = f1_score(actual_y, pred_y, average=None)\n",
        "recall_score_list = recall_score(actual_y, pred_y, average=None)\n",
        "precision_score_list = precision_score(actual_y, pred_y, average=None)\n",
        "print(np.mean(f1_score(actual_y, pred_y, average=None)))\n",
        "print(recall_score(actual_y, pred_y, average=None))\n",
        "print(precision_score(actual_y, pred_y, average=None))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Store into Google Drive\n",
        "with open(\"/content/drive/MyDrive/cs769-project/output/evaluation_val.txt\", \"w\") as outfile:\n",
        "  for scores in [f1_score_list, recall_score_list, precision_score_list]:\n",
        "    for value in scores:\n",
        "      outfile.write(\"%.4f\\t\" % value)\n",
        "    outfile.write('\\n')"
      ],
      "metadata": {
        "id": "ZKgMoroGNlH3"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trial_test_ds = test_ds.map(process_label, num_parallel_calls=tf.data.experimental.AUTOTUNE, deterministic=False)\n",
        "test_dataset = trial_test_ds.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "pL3yiGgsMV4S"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, we are showing the average F-1 score on the test set."
      ],
      "metadata": {
        "id": "DGVWsgx3SnAg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pred_test_result = biLSTM_model.predict(test_dataset)"
      ],
      "metadata": {
        "id": "Ce58pi3DVB_U"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_y = []\n",
        "actual_y = []"
      ],
      "metadata": {
        "id": "4ETdw8jSVFnE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "i = 0 \n",
        "for _, labels in test_dataset:\n",
        "  for label in labels.numpy():\n",
        "    pred_label = tf.cast(tf.math.sigmoid(pred_test_result[i]) > 0.5, tf.float32).numpy()\n",
        "    i += 1\n",
        "    pred_y.append(pred_label)\n",
        "    actual_y.append(label)"
      ],
      "metadata": {
        "id": "qtKvHH7gVHc0"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f1_score_list = f1_score(actual_y, pred_y, average=None)\n",
        "recall_score_list = recall_score(actual_y, pred_y, average=None)\n",
        "precision_score_list = precision_score(actual_y, pred_y, average=None)\n",
        "print(np.mean(f1_score(actual_y, pred_y, average=None)))\n",
        "print(recall_score(actual_y, pred_y, average=None))\n",
        "print(precision_score(actual_y, pred_y, average=None))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dlQGAbfUVLJR",
        "outputId": "cb8581c4-d061-48a9-d0a2-2be28d969cf4"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.4273184637262085\n",
            "[0.59722222 0.76136364 0.28282828 0.2875     0.26780627 0.3037037\n",
            " 0.29411765 0.35211268 0.28915663 0.24503311 0.19850187 0.37398374\n",
            " 0.21621622 0.27184466 0.61538462 0.89204545 0.33333333 0.52795031\n",
            " 0.77731092 0.26086957 0.41935484 0.3125     0.20689655 0.09090909\n",
            " 0.57142857 0.46794872 0.41134752 0.55008394]\n",
            "[0.57333333 0.73897059 0.448      0.24731183 0.28398792 0.29927007\n",
            " 0.32142857 0.35335689 0.5        0.25694444 0.29120879 0.56097561\n",
            " 0.42105263 0.34146341 0.6        0.91812865 1.         0.49418605\n",
            " 0.7312253  0.28571429 0.53424658 0.71428571 0.19607843 0.25\n",
            " 0.59259259 0.48993289 0.56862745 0.57687793]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/drive/MyDrive/cs769-project/output/evaluation_test.txt\", \"w\") as outfile:\n",
        "  for scores in [f1_score_list, recall_score_list, precision_score_list]:\n",
        "    for value in scores:\n",
        "      outfile.write(\"%.4f\\t\" % value)\n",
        "    outfile.write('\\n')"
      ],
      "metadata": {
        "id": "_DDd6GhXVNEb"
      },
      "execution_count": 65,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Wisc GoEmotions_biLSTM.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}